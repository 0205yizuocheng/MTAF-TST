# 伊犁数据集
area1: 经度 纬度
左上：(81.37222527148107, 43.865844613317215)
左下：(81.39375436229174, 43.8657724618653)
右上：(81.37214014281464, 43.85215922864556)
右下：(81.39366431018051, 43.852087111449)

area2:
(81.33432084016559, 43.91971371602819)
(81.34727491905892, 43.91967508261576)
(81.33427849984683, 43.91215078504793)
(81.34723093823978, 43.91211216177209)

area3:
(81.27444392017387, 43.90060540152312)
(81.29648382713151, 43.90055034497621)
(81.2743889308194, 43.88863064935749)
(81.29642442187084, 43.88857561568201)

area4:
(81.37024904037513, 43.88836027437814)
(81.38842495193974, 43.88829993988352)
(81.37018714963405, 43.87836638269983)
(81.38836002309941, 43.87830606912416)

area5: 
(81.3820098887512, 43.91695319009243)
(81.39969626898824, 43.916892696089505)
(81.38197360558496, 43.91128101961508)
(81.39965830608233, 43.91122053751677)

## 土地覆盖类别（Label）
* 0 Water
* 1 Sparse vegetation 
* 2 Cropland
* 3 Forest
* 4 Build-up
* 5 bare

## 光学数据（Optic）
1. 分辨率为10米
2. 2021.4-2021.12 共40个时相
3. 每个时相的光谱：依次为B，G，R，NIR

## 光学数据（SAR）
1. 分辨率为10米
2. 2021.4-2021.12 共46个时相
3. 每个时相的光谱：依次为VV，VH

# 武汉数据集

## 土地覆盖类别（Label）
* 0 Tree cover
* 1 Grassland 
* 2 Cropland
* 3 Built-up
* 4 Bare/sparse vegetation
* 5 Permanent water bodies
* 6 Herbaceous wetland
  
```
当前标签文件中的标签为1，2，3，4，5，6，8，9
使用changlabel函数（来自大服务器的test代码）变为0，1, 2，3，4，5，6
print("修改之前：",np.unique(im_data,return_counts=True))
        im_data[im_data==1]=0
        im_data[im_data==2]=1
        im_data[im_data==3]=2
        im_data[im_data==4]=3
        im_data[im_data==5]=4
        im_data[im_data==7]=5
        im_data[im_data==8]=6
        print("修改之后：",np.unique(im_data,return_counts=True))
```

## 光学数据（Optic）
1. 分辨率为10米
2. 2020.3-2020.11 共16个时相
3. 每个时相的光谱：依次为B，G，R，NIR

## 光学数据（SAR）
1. 分辨率为10米
2. 2020.3-2020.11 共23个时相
3. 每个时相的光谱：依次为VV，VH

# 文件夹说明
* gt,P和S为裁剪之后的原始Patch
* *_norm为经过了标准化的结果（标准化方式：取整个数据集中每个波段的均值和方差）
* *_norm_aug为标准化之后的Patch又进行了水平和竖直翻转
* train.csv,test.csv,val.csv为未经过翻转之前的数据集，按照6：2：2划分的
* trainlist.csv为遍历train.csv，添加训练集中每个翻转之后的Patch的文件名添加到训练集csv

# clip.py文件使用
1. 制作一个裁剪(image2patch)
2. 标准化(Norm):裁剪后的光学和SAR数据分别处理，参数：patch路径，长度，波段数，窗口大小
3. 训练集划分(getcsv)：在翻转之前，得到训练集patch
4. 训练集翻转：将所有patch均翻转
5. 训练集中添加翻转后的patch(csvAddHV)


